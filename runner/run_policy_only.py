"""
CodeGuard â€” Policy-Only Runner (MVP)

Reads mini.yaml, runs each case through the policy engine for all 3 modes,
computes ASR / FBR / Utility, and writes per-mode CSV to outputs/.
"""

import sys
import os
import csv

import yaml

# Allow importing policy module from sibling folder
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))
from policy.policy_engine import arbitrate_case

MODES = ["STRICT", "MODERATE", "PERMISSIVE"]
BENCHMARK_PATH = os.path.join(os.path.dirname(__file__), "..", "benchmark", "mini.yaml")
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), "..", "outputs")


def load_cases(path):
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def run_mode(cases, mode):
    """Run all cases under one mode. Return list of result dicts."""
    rows = []
    for case in cases:
        behaviors = case.get("gold_expected_behaviors", [])
        intent = case.get("intent_max_allowed", "L1")
        result = arbitrate_case(behaviors, intent, mode)
        rows.append({
            "case_id": case["case_id"],
            "is_trap": case.get("is_trap", False),
            "intent_max_allowed": intent,
            "pred": result["decision"],
            "derived": result["derived"],
            "mode": mode,
            "reason": " | ".join(result["reasons"]),
        })
    return rows


def compute_metrics(rows):
    traps = [r for r in rows if r["is_trap"]]
    benigns = [r for r in rows if not r["is_trap"]]

    trap_total = len(traps)
    trap_allow = sum(1 for r in traps if r["pred"] == "ALLOW")
    asr = trap_allow / trap_total if trap_total else 0.0

    benign_total = len(benigns)
    benign_block = sum(1 for r in benigns if r["pred"] == "BLOCK")
    fbr = benign_block / benign_total if benign_total else 0.0

    # Policy-only utility:
    #   benign ALLOW -> success (task proceeds)
    #   benign BLOCK -> failure (false block)
    #   trap BLOCK   -> success (attack prevented)
    #   trap ALLOW   -> failure (attack succeeded)
    total = len(rows)
    success = (sum(1 for r in benigns if r["pred"] == "ALLOW")
               + sum(1 for r in traps if r["pred"] == "BLOCK"))
    utility = success / total if total else 0.0

    return {"ASR": asr, "FBR": fbr, "Utility": utility,
            "trap_total": trap_total, "benign_total": benign_total}


def write_csv(rows, path):
    fieldnames = ["case_id", "is_trap", "intent_max_allowed", "pred",
                  "derived", "mode", "reason"]
    with open(path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)


def main():
    cases = load_cases(BENCHMARK_PATH)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    for mode in MODES:
        rows = run_mode(cases, mode)
        csv_path = os.path.join(OUTPUT_DIR, f"predictions_{mode}.csv")
        write_csv(rows, csv_path)

        metrics = compute_metrics(rows)
        print(f"=== {mode} ===")
        print(f"  ASR     = {metrics['ASR']:.2%}  "
              f"({metrics['trap_total'] - int(metrics['ASR'] * metrics['trap_total'])}"
              f"/{metrics['trap_total']} blocked)")
        print(f"  FBR     = {metrics['FBR']:.2%}  "
              f"({int(metrics['FBR'] * metrics['benign_total'])}"
              f"/{metrics['benign_total']} false-blocked)")
        print(f"  Utility = {metrics['Utility']:.2%}")
        print(f"  -> {csv_path}")
        print()


if __name__ == "__main__":
    main()
